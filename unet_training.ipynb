{
  "cells": [
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a629980074ebbdaf",
        "outputId": "2ae671db-57c6-4aba-a770-e69654a33b12"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Pytorch-UNet'...\n",
            "remote: Enumerating objects: 618, done.\u001b[K\n",
            "remote: Total 618 (delta 0), reused 0 (delta 0), pack-reused 618 (from 1)\u001b[K\n",
            "Receiving objects: 100% (618/618), 47.42 MiB | 36.08 MiB/s, done.\n",
            "Resolving deltas: 100% (334/334), done.\n"
          ]
        }
      ],
      "execution_count": 1,
      "source": [
        "!git clone https://github.com/milesial/Pytorch-UNet"
      ],
      "id": "a629980074ebbdaf"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Pytorch-UNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIBSRHrUg580",
        "outputId": "287f3265-cf47-472d-bed9-5755e5da6188"
      },
      "id": "YIBSRHrUg580",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Pytorch-UNet'\n",
            "/content/Pytorch-UNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-06-29T11:19:28.536702Z",
          "start_time": "2025-06-29T11:19:28.478353Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "794f8b26-b8be-4492-d21f-07eeca263d93"
      },
      "source": [
        "from unet import UNet\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = UNet(n_channels=8, n_classes=1, bilinear=True)\n",
        "model.to(device)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (inc): DoubleConv(\n",
              "    (double_conv): Sequential(\n",
              "      (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (down1): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down4): Down(\n",
              "    (maxpool_conv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): DoubleConv(\n",
              "        (double_conv): Sequential(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up1): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up2): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up3): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up4): Up(\n",
              "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "    (conv): DoubleConv(\n",
              "      (double_conv): Sequential(\n",
              "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (outc): OutConv(\n",
              "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T7mGTZXhIBS",
        "outputId": "064c5f22-8f3f-46cd-f60d-79fa6c16e5ef"
      },
      "id": "-T7mGTZXhIBS",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-29T11:43:08.977363Z",
          "start_time": "2025-06-29T11:43:08.972900Z"
        },
        "id": "4835c4825521684"
      },
      "cell_type": "code",
      "source": [
        "import tifffile\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from os import listdir\n",
        "from os.path import splitext, isfile, join\n",
        "import logging\n",
        "from PIL import Image\n",
        "from multiprocessing import Pool\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F # Import F for padding\n",
        "\n",
        "def load_image(filename):\n",
        "    # This function is not needed for .tif files as tifffile.imread handles loading\n",
        "    pass\n",
        "\n",
        "def unique_mask_values(idx, mask_dir, mask_suffix):\n",
        "    mask_file = list(mask_dir.glob(idx + mask_suffix + '.*'))\n",
        "    if not mask_file:\n",
        "        raise FileNotFoundError(f\"Mask file not found for ID: {idx}\")\n",
        "    mask_file = mask_file[0]\n",
        "    mask = tifffile.imread(str(mask_file)).astype(np.uint8)\n",
        "    if mask.ndim == 3:\n",
        "        mask = mask[:, :, 0] # Take the first channel if it's an RGB mask\n",
        "    return np.unique(mask)\n",
        "\n",
        "\n",
        "class BasicDataset(Dataset):\n",
        "    def __init__(self, images_dir: str, mask_dir: str, scale: float = 1.0, mask_suffix: str = '', pad_to_multiple: int = 32):\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.mask_dir = Path(mask_dir)\n",
        "        assert 0 < scale <= 1, 'Scale must be between 0 and 1'\n",
        "        self.scale = scale\n",
        "        self.mask_suffix = mask_suffix\n",
        "        self.pad_to_multiple = pad_to_multiple # Added padding attribute\n",
        "\n",
        "        self.ids = [splitext(file)[0] for file in listdir(images_dir) if isfile(join(images_dir, file)) and not file.startswith('.')]\n",
        "        if not self.ids:\n",
        "            raise RuntimeError(f'No input file found in {images_dir}, make sure you put your images there')\n",
        "\n",
        "        logging.info(f'Creating dataset with {len(self.ids)} examples')\n",
        "        logging.info('Scanning mask files to determine unique values')\n",
        "        # Use a smaller pool size or adjust based on your system resources if needed\n",
        "        with Pool(processes=4) as p:\n",
        "             unique = list(tqdm(\n",
        "                 p.imap(partial(unique_mask_values, mask_dir=self.mask_dir, mask_suffix=self.mask_suffix), self.ids),\n",
        "                 total=len(self.ids)\n",
        "             ))\n",
        "\n",
        "\n",
        "        self.mask_values = list(sorted(np.unique(np.concatenate(unique)).tolist()))\n",
        "        logging.info(f'Unique mask values: {self.mask_values}')\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.ids[idx]\n",
        "        img_file = list(self.images_dir.glob(name + '.*'))\n",
        "        mask_file = list(self.mask_dir.glob(name + self.mask_suffix + '.*'))\n",
        "\n",
        "        if not img_file:\n",
        "             raise FileNotFoundError(f\"Image file not found for ID: {name}\")\n",
        "        if not mask_file:\n",
        "             raise FileNotFoundError(f\"Mask file not found for ID: {name}\")\n",
        "\n",
        "        img = tifffile.imread(str(img_file[0])).astype(np.float32) / 255.0  # [H, W, C]\n",
        "        mask = tifffile.imread(str(mask_file[0])).astype(np.uint8)\n",
        "\n",
        "        # Handle potential scaling (optional, based on original BasicDataset)\n",
        "        # if self.scale != 1.0:\n",
        "        #     img = self.scale_image(img, self.scale)\n",
        "        #     mask = self.scale_image(mask, self.scale)\n",
        "\n",
        "        if img.ndim == 3:\n",
        "            img = img.transpose(2, 0, 1)  # to [C, H, W]\n",
        "        elif img.ndim == 2: # Handle grayscale images by adding a channel dimension\n",
        "             img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        if mask.ndim == 3:\n",
        "            mask = mask[:, :, 0]  # in case of RGB mask\n",
        "\n",
        "        # Convert mask to binary (0 and 1)\n",
        "        # Assuming all non-zero values represent the foreground\n",
        "        mask = (mask > 0).astype(np.uint8)\n",
        "\n",
        "        # Convert to tensors before padding\n",
        "        img_tensor = torch.from_numpy(img)\n",
        "        mask_tensor = torch.from_numpy(mask).long()\n",
        "\n",
        "        # Pad images and masks to be divisible by pad_to_multiple\n",
        "        _, h, w = img_tensor.shape\n",
        "        pad_h = (self.pad_to_multiple - (h % self.pad_to_multiple)) % self.pad_to_multiple\n",
        "        pad_w = (self.pad_to_multiple - (w % self.pad_to_multiple)) % self.pad_to_multiple\n",
        "\n",
        "        # Pad image tensor (C, H, W)\n",
        "        img_tensor = F.pad(img_tensor, (0, pad_w, 0, pad_h))\n",
        "\n",
        "        # Pad mask tensor (H, W) - need to add channel dimension for F.pad\n",
        "        mask_tensor = mask_tensor.unsqueeze(0) # Add channel dimension\n",
        "        mask_tensor = F.pad(mask_tensor, (0, pad_w, 0, pad_h))\n",
        "        mask_tensor = mask_tensor.squeeze(0) # Remove channel dimension\n",
        "\n",
        "        return {\n",
        "            'image': img_tensor,\n",
        "            'mask': mask_tensor\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(mask_values, pil_img, scale, is_mask):\n",
        "        # This method is from the original BasicDataset but is not directly used\n",
        "        # with tifffile. It's kept here for reference or if needed for other image types\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def scale_image(img, scale):\n",
        "        # Placeholder for image scaling if needed\n",
        "        # You would need to implement image resizing here (e.g., using OpenCV or PIL)\n",
        "        return img"
      ],
      "id": "4835c4825521684",
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install importlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9cduft31uXc",
        "outputId": "8ba7543f-8495-49bb-9401-5d69e4079447"
      },
      "id": "C9cduft31uXc",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting importlib\n",
            "  Downloading importlib-1.0.4.zip (7.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: importlib\n",
            "  Building wheel for importlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for importlib: filename=importlib-1.0.4-py3-none-any.whl size=5850 sha256=cf25b2101065a98a778f79e69c181940ff9729235ad08bba3cb1d1e6b4262f21\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/4a/6e/7c4a313549653a504574fa29f907139c752051ef05210df605\n",
            "Successfully built importlib\n",
            "Installing collected packages: importlib\n",
            "Successfully installed importlib-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "from utils.dice_score import multiclass_dice_coeff, dice_coeff\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evaluate(net, dataloader, device, amp):\n",
        "    net.eval()\n",
        "    num_val_batches = len(dataloader)\n",
        "    dice_score = 0\n",
        "\n",
        "    # iterate over the validation set\n",
        "    with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
        "        for batch in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', leave=False):\n",
        "            image, mask_true = batch['image'], batch['mask']\n",
        "\n",
        "            # move images and labels to correct device and type\n",
        "            image = image.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
        "            mask_true = mask_true.to(device=device, dtype=torch.long)\n",
        "\n",
        "            # predict the mask\n",
        "            mask_pred = net(image)\n",
        "\n",
        "            if net.n_classes == 1:\n",
        "                assert mask_true.min() >= 0 and mask_true.max() <= 1, 'True mask indices should be in [0, 1]'\n",
        "                mask_pred = F.sigmoid(mask_pred) # Apply sigmoid here\n",
        "                mask_pred = (mask_pred > 0.5).float()\n",
        "                # Squeeze the predicted mask to remove the channel dimension\n",
        "                mask_pred = mask_pred.squeeze(1)\n",
        "                # compute the Dice score\n",
        "                dice_score += dice_coeff(mask_pred, mask_true, reduce_batch_first=False)\n",
        "            else:\n",
        "                assert mask_true.min() >= 0 and mask_true.max() < net.n_classes, 'True mask indices should be in [0, n_classes['\n",
        "                # convert to one-hot format\n",
        "                mask_true = F.one_hot(mask_true, net.n_classes).permute(0, 3, 1, 2).float()\n",
        "                mask_pred = F.one_hot(mask_pred.argmax(dim=1), net.n_classes).permute(0, 3, 1, 2).float()\n",
        "                # compute the Dice score, ignoring background\n",
        "                dice_score += multiclass_dice_coeff(mask_pred[:, 1:], mask_true[:, 1:], reduce_batch_first=False)\n",
        "\n",
        "    net.train()\n",
        "    return dice_score / max(num_val_batches, 1)"
      ],
      "metadata": {
        "id": "kQ0y2QQF5JG1"
      },
      "id": "kQ0y2QQF5JG1",
      "execution_count": 48,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-29T11:43:11.479796Z",
          "start_time": "2025-06-29T11:43:11.470470Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f1186f2257f7ed50",
        "outputId": "35607502-0ce5-448d-ab5a-69bff4e3af5e"
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from pathlib import Path\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "import wandb\n",
        "from unet import UNet\n",
        "from utils.dice_score import dice_loss\n",
        "\n",
        "dir_checkpoint = Path('./checkpoints/')\n",
        "\n",
        "import importlib\n",
        "import utils.dice_score\n",
        "importlib.reload(utils.dice_score)\n",
        "from utils.dice_score import dice_loss\n",
        "\n",
        "\n",
        "def train_model(\n",
        "        model,\n",
        "        device,\n",
        "        epochs: int = 5,\n",
        "        batch_size: int = 1,\n",
        "        learning_rate: float = 1e-9,\n",
        "        val_percent: float = 0.1,\n",
        "        save_checkpoint: bool = True,\n",
        "        img_scale: float = 0.5,\n",
        "        amp: bool = False,\n",
        "        weight_decay: float = 1e-8,\n",
        "        momentum: float = 0.999,\n",
        "        gradient_clipping: float = 1.0,\n",
        "):\n",
        "    dataset = BasicDataset('/content/drive/MyDrive/Brick_Data_Train/Brick_Data_Train/Image', '/content/drive/MyDrive/Brick_Data_Train/Brick_Data_Train/Mask')\n",
        "\n",
        "\n",
        "    # 2. Split into train / validation partitions\n",
        "    n_val = int(len(dataset) * val_percent)\n",
        "    n_train = len(dataset) - n_val\n",
        "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "    # 3. Create data loaders\n",
        "    loader_args = dict(batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True)\n",
        "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
        "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
        "\n",
        "    # (Initialize logging)\n",
        "    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
        "    experiment.config.update(\n",
        "        dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
        "             val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale, amp=amp)\n",
        "    )\n",
        "\n",
        "    logging.info(f'''Starting training:\n",
        "        Epochs:          {epochs}\n",
        "        Batch size:      {batch_size}\n",
        "        Learning rate:   {learning_rate}\n",
        "        Training size:   {n_train}\n",
        "        Validation size: {n_val}\n",
        "        Checkpoints:     {save_checkpoint}\n",
        "        Device:          {device.type}\n",
        "        Images scaling:  {img_scale}\n",
        "        Mixed Precision: {amp}\n",
        "    ''')\n",
        "\n",
        "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                              lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
        "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
        "    criterion = nn.BCEWithLogitsLoss() # Use BCEWithLogitsLoss for binary segmentation\n",
        "    global_step = 0\n",
        "\n",
        "    # 5. Begin training\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
        "            for batch in train_loader:\n",
        "                images, true_masks = batch['image'], batch['mask']\n",
        "\n",
        "                assert images.shape[1] == model.n_channels, \\\n",
        "                    f'Network has been defined with {model.n_channels} input channels, ' \\\n",
        "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
        "                    'the images are loaded correctly.'\n",
        "\n",
        "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
        "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
        "\n",
        "                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
        "                    masks_pred = model(images)\n",
        "                    if model.n_classes == 1:\n",
        "                        loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
        "                        loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
        "                    else:\n",
        "                        loss = criterion(masks_pred, true_masks)\n",
        "                        loss += dice_loss(\n",
        "                            F.softmax(masks_pred, dim=1).float(),\n",
        "                            F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
        "                            multiclass=True\n",
        "                        )\n",
        "\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                grad_scaler.scale(loss).backward()\n",
        "                grad_scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
        "                grad_scaler.step(optimizer)\n",
        "                grad_scaler.update()\n",
        "\n",
        "                pbar.update(images.shape[0])\n",
        "                global_step += 1\n",
        "                epoch_loss += loss.item()\n",
        "                experiment.log({\n",
        "                    'train loss': loss.item(),\n",
        "                    'step': global_step,\n",
        "                    'epoch': epoch\n",
        "                })\n",
        "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
        "\n",
        "                # Evaluation round\n",
        "                division_step = (n_train // (5 * batch_size))\n",
        "                if division_step > 0:\n",
        "                    if global_step % division_step == 0:\n",
        "                        histograms = {}\n",
        "                        for tag, value in model.named_parameters():\n",
        "                            if not value.requires_grad:\n",
        "                                continue  # skip frozen layers\n",
        "                            tag = tag.replace('/', '.')\n",
        "                            if not (torch.isinf(value) | torch.isnan(value)).any():\n",
        "                                histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
        "                            if not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():\n",
        "                                histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
        "\n",
        "                        val_score = evaluate(model, val_loader, device, amp)\n",
        "                        scheduler.step(val_score)\n",
        "\n",
        "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
        "                        try:\n",
        "                            experiment.log({\n",
        "                                'learning rate': optimizer.param_groups[0]['lr'],\n",
        "                                'validation Dice': val_score,\n",
        "                                'images': wandb.Image(images[0].cpu()),\n",
        "                                'masks': {\n",
        "                                    'true': wandb.Image(true_masks[0].float().cpu()),\n",
        "                                    'pred': wandb.Image(masks_pred.argmax(dim=1)[0].float().cpu()),\n",
        "                                },\n",
        "                                'step': global_step,\n",
        "                                'epoch': epoch,\n",
        "                                **histograms\n",
        "                            })\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "        if save_checkpoint:\n",
        "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
        "            state_dict = model.state_dict()\n",
        "            torch.save(state_dict, str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
        "            logging.info(f'Checkpoint {epoch} saved!')\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')\n",
        "    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=5, help='Number of epochs')\n",
        "    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=1, help='Batch size')\n",
        "    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,\n",
        "                        help='Learning rate', dest='lr')\n",
        "    parser.add_argument('--load', '-f', type=str, default=False, help='Load model from a .pth file')\n",
        "    parser.add_argument('--scale', '-s', type=float, default=0.5, help='Downscaling factor of the images')\n",
        "    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0,\n",
        "                        help='Percent of the data that is used as validation (0-100)')\n",
        "    parser.add_argument('--amp', action='store_true', default=False, help='Use mixed precision')\n",
        "    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')\n",
        "    parser.add_argument('--classes', '-c', type=int, default=2, help='Number of classes')\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "train_model(model=model, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
      ],
      "id": "f1186f2257f7ed50",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:00<00:00, 211.62it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆███████</td></tr><tr><td>step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>step</td><td>65</td></tr><tr><td>train loss</td><td>nan</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">kind-sun-16</strong> at: <a href='https://wandb.ai/anony-moose-295675187834649230/U-Net/runs/68hyu0xc?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4' target=\"_blank\">https://wandb.ai/anony-moose-295675187834649230/U-Net/runs/68hyu0xc?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4</a><br> View project at: <a href='https://wandb.ai/anony-moose-295675187834649230/U-Net?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4' target=\"_blank\">https://wandb.ai/anony-moose-295675187834649230/U-Net?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250629_181428-68hyu0xc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Pytorch-UNet/wandb/run-20250629_181535-o9qqq38m</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anony-moose-295675187834649230/U-Net/runs/o9qqq38m?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4' target=\"_blank\">winter-night-17</a></strong> to <a href='https://wandb.ai/anony-moose-295675187834649230/U-Net?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anony-moose-295675187834649230/U-Net?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4' target=\"_blank\">https://wandb.ai/anony-moose-295675187834649230/U-Net?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anony-moose-295675187834649230/U-Net/runs/o9qqq38m?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4' target=\"_blank\">https://wandb.ai/anony-moose-295675187834649230/U-Net/runs/o9qqq38m?apiKey=45cfab18f8b174dfc0b61c6f43774954f08eefb4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Do NOT share these links with anyone. They can be used to claim your runs."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-51-3731158096.py:78: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Epoch 1/5:  15%|█▌        | 2/13 [00:00<00:01,  7.76img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  9.74batch/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 4/13 [00:00<00:01,  6.46img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  8.95batch/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 6/13 [00:00<00:01,  6.34img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 8/13 [00:01<00:00,  6.70img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  8.51batch/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 10/13 [00:01<00:00,  6.61img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 12/13 [00:01<00:00,  7.01img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  8.99batch/s]\u001b[A\n",
            "Epoch 1/5: 100%|██████████| 13/13 [00:01<00:00,  6.53img/s, loss (batch)=nan]\n",
            "Epoch 2/5:   8%|▊         | 1/13 [00:00<00:01,  7.05img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 2/5:  23%|██▎       | 3/13 [00:00<00:01,  5.57img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  9.68batch/s]\u001b[A\n",
            "Epoch 2/5:  38%|███▊      | 5/13 [00:00<00:01,  6.30img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  4.90batch/s]\u001b[A\n",
            "Epoch 2/5:  54%|█████▍    | 7/13 [00:01<00:01,  5.02img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  2.93batch/s]\u001b[A\n",
            "Epoch 2/5:  69%|██████▉   | 9/13 [00:01<00:01,  3.43img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  6.95batch/s]\u001b[A\n",
            "Epoch 2/5:  85%|████████▍ | 11/13 [00:02<00:00,  4.18img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  7.91batch/s]\u001b[A\n",
            "Epoch 2/5: 100%|██████████| 13/13 [00:02<00:00,  4.71img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  5.16batch/s]\u001b[A\n",
            "Epoch 2/5: 100%|██████████| 13/13 [00:03<00:00,  4.32img/s, loss (batch)=nan]\n",
            "Epoch 3/5:  15%|█▌        | 2/13 [00:00<00:02,  4.55img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  7.83batch/s]\u001b[A\n",
            "Epoch 3/5:  31%|███       | 4/13 [00:00<00:01,  5.10img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  7.22batch/s]\u001b[A\n",
            "Epoch 3/5:  46%|████▌     | 6/13 [00:01<00:01,  5.33img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  6.93batch/s]\u001b[A\n",
            "Epoch 3/5:  62%|██████▏   | 8/13 [00:01<00:00,  5.35img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  7.06batch/s]\u001b[A\n",
            "Epoch 3/5:  77%|███████▋  | 10/13 [00:01<00:00,  5.08img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  7.03batch/s]\u001b[A\n",
            "Epoch 3/5:  92%|█████████▏| 12/13 [00:02<00:00,  5.27img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  7.56batch/s]\u001b[A\n",
            "Epoch 3/5: 100%|██████████| 13/13 [00:02<00:00,  5.12img/s, loss (batch)=nan]\n",
            "Epoch 4/5:   8%|▊         | 1/13 [00:00<00:02,  5.30img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 4/5:  23%|██▎       | 3/13 [00:00<00:01,  5.04img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 4/5:  38%|███▊      | 5/13 [00:00<00:01,  6.24img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 4/5:  54%|█████▍    | 7/13 [00:01<00:00,  6.75img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  8.52batch/s]\u001b[A\n",
            "Epoch 4/5:  69%|██████▉   | 9/13 [00:01<00:00,  6.64img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 4/5:  85%|████████▍ | 11/13 [00:01<00:00,  6.96img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  8.68batch/s]\u001b[A\n",
            "Epoch 4/5: 100%|██████████| 13/13 [00:01<00:00,  6.75img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 4/5: 100%|██████████| 13/13 [00:02<00:00,  6.00img/s, loss (batch)=nan]\n",
            "Epoch 5/5:  15%|█▌        | 2/13 [00:00<00:01,  7.26img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 5/5:  31%|███       | 4/13 [00:00<00:01,  7.69img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 5/5:  46%|████▌     | 6/13 [00:00<00:00,  7.61img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  8.37batch/s]\u001b[A\n",
            "Epoch 5/5:  62%|██████▏   | 8/13 [00:01<00:00,  7.07img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Epoch 5/5:  77%|███████▋  | 10/13 [00:01<00:00,  7.16img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  9.79batch/s]\u001b[A\n",
            "Epoch 5/5:  92%|█████████▏| 12/13 [00:01<00:00,  7.23img/s, loss (batch)=nan]\n",
            "Validation round:   0%|          | 0/1 [00:00<?, ?batch/s]\u001b[A\n",
            "Validation round: 100%|██████████| 1/1 [00:00<00:00,  8.13batch/s]\u001b[A\n",
            "Epoch 5/5: 100%|██████████| 13/13 [00:01<00:00,  6.87img/s, loss (batch)=nan]\n"
          ]
        }
      ],
      "execution_count": 51
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}